{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- loading data set using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ImageLabelDataset(Dataset):\n",
    "    def __init__(self, root_dir, data_types):\n",
    "        self.data = {}\n",
    "        for data_type in data_types:\n",
    "            data_path = os.path.join(root_dir, data_type)\n",
    "            image_folder_path = os.path.join(data_path, \"images\")\n",
    "            label_folder_path = os.path.join(data_path, \"labels\", \"json\")\n",
    "            images = []\n",
    "            labels = []\n",
    "            for image_file in os.listdir(image_folder_path):\n",
    "                image_path = os.path.join(image_folder_path, image_file)\n",
    "                json_file = image_file.split('.')[0] + '.json'\n",
    "                label_path = os.path.join(label_folder_path, json_file)\n",
    "                if os.path.exists(label_path):\n",
    "                    images.append(image_path)\n",
    "                    labels.append(label_path)\n",
    "            self.data[data_type] = {\"images\": images, \"labels\": labels}\n",
    "\n",
    "    def __len__(self):\n",
    "        total_images = 0\n",
    "        for data_type in self.data:\n",
    "            total_images += len(self.data[data_type][\"images\"])\n",
    "        return total_images\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "     data_type = None\n",
    "     image_idx = None\n",
    "     for dt, data in self.data.items():\n",
    "        if idx < len(data['images']):\n",
    "            data_type = dt\n",
    "            image_idx = idx\n",
    "            break\n",
    "        else:\n",
    "            idx -= len(data['images'])\n",
    "     if data_type is not None and image_idx is not None:\n",
    "        image_path = self.data[data_type][\"images\"][image_idx]\n",
    "        label_path = self.data[data_type][\"labels\"][image_idx]\n",
    "        return image_path, label_path\n",
    "     else:\n",
    "        raise IndexError(\"Index out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- visualizing some of the labeled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_images(data_loader, num_batches):\n",
    "    colors = {\"bin\": (255, 0, 0), \"dolly\": (0, 255, 0), \"jack\": (0, 0, 255)}\n",
    "    \n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        if batch_idx >= num_batches:\n",
    "            break\n",
    "        \n",
    "        images, labels = batch\n",
    "        for image_path, label_path in zip(images, labels):\n",
    "            image_cv2 = cv2.imread(image_path)\n",
    "            image_cv2 = cv2.cvtColor(image_cv2, cv2.COLOR_BGR2RGB)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.imshow(image_cv2)\n",
    "\n",
    "            with open(label_path, 'r') as f:\n",
    "                labels = json.load(f)\n",
    "\n",
    "            for bbox in labels:\n",
    "                left = bbox[\"Left\"]\n",
    "                top = bbox[\"Top\"]\n",
    "                right = bbox[\"Right\"]\n",
    "                bottom = bbox[\"Bottom\"]\n",
    "                class_name = bbox[\"ObjectClassName\"]\n",
    "                color = colors.get(class_name, (0, 0, 0))\n",
    "            \n",
    "\n",
    "                cv2.rectangle(image_cv2, (left, top), (right, bottom), color, 2)\n",
    "                cv2.putText(image_cv2, class_name, (left, top - 5), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 4)\n",
    "\n",
    "            plt.imshow(image_cv2)\n",
    "            plt.title(image_path)\n",
    "            plt.show()\n",
    "           \n",
    "\n",
    "\n",
    "root_dir = \"data\"\n",
    "dataset_train = ImageLabelDataset(root_dir, [\"Training\"])\n",
    "dataset_test = ImageLabelDataset(root_dir, [\"Testing\"])\n",
    "batch_size = 2\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "num_batches_to_visualize = 1\n",
    "print(\"Visualizing training images:\")\n",
    "visualize_images(train_loader, num_batches_to_visualize)\n",
    "\n",
    "print(\"Visualizing testing images:\")\n",
    "visualize_images(test_loader, num_batches_to_visualize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- adding agmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "def augment_and_save_images(data_loader, output_dir, num_batches=1):\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        if batch_idx >= num_batches:\n",
    "            break  \n",
    "        augmentation = A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            A.RGBShift(r_shift_limit=25, g_shift_limit=25, b_shift_limit=25, p=0.5),\n",
    "            A.RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
    "            A.Blur(blur_limit=(3, 7), p=0.5),\n",
    "        ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels', 'class_ids']))\n",
    "        \n",
    "        images, labels = batch\n",
    "    \n",
    "        for image_path, label_path in zip(images, labels):\n",
    "            image = cv2.imread(image_path)\n",
    "            filename = os.path.splitext(os.path.basename(image_path))[0] \n",
    "            output_img_path = os.path.join(output_dir, f\"{filename}_a.jpg\") \n",
    "            output_label_path = os.path.join(os.path.dirname(label_path), f\"{filename}_a.json\") \n",
    "            \n",
    "            if os.path.exists(label_path):\n",
    "                with open(label_path, 'r') as f:\n",
    "                    try:\n",
    "                        original_labels = json.load(f)\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Error: Unable to parse JSON file: {label_path}\")\n",
    "                        continue\n",
    "\n",
    "                bboxes = []\n",
    "                class_labels = []\n",
    "                class_ids = []  # Add class IDs list\n",
    "                for bbox in original_labels:\n",
    "                    try:\n",
    "                        class_name = bbox[\"ObjectClassName\"]\n",
    "                        class_id = bbox[\"ObjectClassId\"]  # Get class ID\n",
    "                        left = bbox[\"Left\"]\n",
    "                        top = bbox[\"Top\"]\n",
    "                        right = bbox[\"Right\"]\n",
    "                        bottom = bbox[\"Bottom\"]\n",
    "                    except KeyError:\n",
    "                        print(f\"Error: Malformed label in file: {label_path}\")\n",
    "                        continue\n",
    "                    bboxes.append([left, top, right, bottom])\n",
    "                    class_labels.append(class_name)\n",
    "                    class_ids.append(class_id)  # Append class ID\n",
    "\n",
    "                augmented = augmentation(image=image, bboxes=bboxes, class_labels=class_labels, class_ids=class_ids)\n",
    "                augmented_image = augmented['image']\n",
    "                augmented_bboxes = augmented['bboxes']\n",
    "                cv2.imwrite(output_img_path, augmented_image)\n",
    "                with open(output_label_path, 'w') as f_out:\n",
    "                    augmented_labels = []\n",
    "                    for bbox, class_id in zip(augmented_bboxes, class_ids):\n",
    "                        augmented_labels.append({\n",
    "                            \"Left\": int(bbox[0]),\n",
    "                            \"Top\": int(bbox[1]),\n",
    "                            \"Right\": int(bbox[2]),\n",
    "                            \"Bottom\": int(bbox[3]),\n",
    "                            \"ObjectClassName\": class_labels[augmented_bboxes.index(bbox)],\n",
    "                            \"ObjectClassId\": class_id  # Include class ID in augmented JSON\n",
    "                        })\n",
    "                    json.dump(augmented_labels, f_out)\n",
    "\n",
    "root_dir = \"data\"\n",
    "output_dir = \"data/Training/images\"\n",
    "dataset_train = ImageLabelDataset(root_dir, [\"Training\"])\n",
    "batch_size = 3\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=False)\n",
    "num_batches_to_augment = 1\n",
    "\n",
    "print(\"Augmenting and saving training images:\")\n",
    "augment_and_save_images(train_loader, output_dir, num_batches_to_augment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting to yolo format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def convert_to_yolo(bbox):\n",
    "    x_center = (bbox['Left'] + bbox['Right']) / (2)\n",
    "    y_center = (bbox['Top'] + bbox['Bottom']) / (2)\n",
    "    width = (bbox['Right'] - bbox['Left']) \n",
    "    height = (bbox['Bottom'] - bbox['Top']) \n",
    "    return f\"{bbox['ObjectClassId']} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
    "\n",
    "input_folder = \"data/Training/labels/json\"\n",
    "\n",
    "output_folder = \"data/Training/labels/yolo\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "for json_file in os.listdir(input_folder):\n",
    "    if json_file.endswith('.json'):\n",
    "        with open(os.path.join(input_folder, json_file), 'r') as f:\n",
    "            data = json.load(f)\n",
    "        yolo_data = []\n",
    "        for bbox in data:\n",
    "            yolo_data.append(convert_to_yolo(bbox))\n",
    "        output_filename = os.path.splitext(json_file)[0] + '.txt'\n",
    "        with open(os.path.join(output_folder, output_filename), 'w') as f:\n",
    "            f.write('\\n'.join(yolo_data))\n",
    "\n",
    "print(\"Conversion completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def normalize_yolo_labels(image_dir, label_dir):\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith((\".jpg\")):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            label_path = os.path.join(label_dir, os.path.splitext(filename)[0] + \".txt\")\n",
    "\n",
    "            if os.path.exists(label_path):\n",
    "                # Read image dimensions\n",
    "                image = cv2.imread(image_path)\n",
    "                image_height, image_width, _ = image.shape\n",
    "\n",
    "                # Read and normalize labels\n",
    "                with open(label_path, \"r\") as file:\n",
    "                    lines = file.readlines()\n",
    "                    normalized_lines = []\n",
    "                    for line in lines:\n",
    "                        class_id, x_center, y_center, box_width, box_height = map(float, line.strip().split())\n",
    "\n",
    "                        # Normalize bounding box coordinates\n",
    "                        x_center_norm = x_center / image_width\n",
    "                        y_center_norm = y_center / image_height\n",
    "                        box_width_norm = box_width / image_width\n",
    "                        box_height_norm = box_height / image_height\n",
    "\n",
    "                        normalized_line = f\"{int(class_id)} {x_center_norm:.6f} {y_center_norm:.6f} {box_width_norm:.6f} {box_height_norm:.6f}\\n\"\n",
    "                        normalized_lines.append(normalized_line)\n",
    "\n",
    "                # Write normalized labels back to file\n",
    "                with open(label_path, \"w\") as file:\n",
    "                    file.writelines(normalized_lines)\n",
    "\n",
    "# Example usage\n",
    "image_directory = \"data/Training/images\"\n",
    "label_directory = \"data/Training/labels/yolo\"\n",
    "normalize_yolo_labels(image_directory, label_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def create_directories(base_folder, subfolders):\n",
    "    for folder in subfolders:\n",
    "        os.makedirs(os.path.join(base_folder, folder), exist_ok=True)\n",
    "\n",
    "def copy_files_to_folder(file_list, dest_folder):\n",
    "    for file_path in file_list:\n",
    "        shutil.copy(file_path, dest_folder)\n",
    "\n",
    "def split_dataset(image_folder, label_folder, split_ratio=0.2):\n",
    "    # Get the list of image files\n",
    "    image_files = os.listdir(image_folder)\n",
    "    num_images = len(image_files)\n",
    "\n",
    "    # Shuffle the image files\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # Calculate the number of images for validation based on the split ratio\n",
    "    num_val_images = int(split_ratio * num_images)\n",
    "\n",
    "    # Split the image files into training and validation sets\n",
    "    val_image_files = image_files[:num_val_images]\n",
    "    train_image_files = image_files[num_val_images:]\n",
    "\n",
    "    # Create training and validation datasets\n",
    "    train_dataset = {\n",
    "        \"images\": [os.path.join(image_folder, img) for img in train_image_files],\n",
    "        \"labels\": [os.path.join(label_folder, os.path.splitext(img)[0] + '.txt') for img in train_image_files]\n",
    "    }\n",
    "    val_dataset = {\n",
    "        \"images\": [os.path.join(image_folder, img) for img in val_image_files],\n",
    "        \"labels\": [os.path.join(label_folder, os.path.splitext(img)[0] + '.txt') for img in val_image_files]\n",
    "    }\n",
    "\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "# Specify the paths to the image and label folders\n",
    "image_folder = \"data/Training/images\"\n",
    "label_folder = \"data/Training/labels/yolo\"\n",
    "\n",
    "# Split the dataset with a 80-20 split ratio (80% training, 20% validation)\n",
    "train_dataset, val_dataset = split_dataset(image_folder, label_folder, split_ratio=0.2)\n",
    "\n",
    "# Create folders for train and validation datasets\n",
    "train_folder = \"data/Training/train\"\n",
    "val_folder = \"data/Training/validation\"\n",
    "create_directories(train_folder, [\"images\", \"labels\"])\n",
    "create_directories(val_folder, [\"images\", \"labels\"])\n",
    "\n",
    "# Copy images and labels to train folder\n",
    "copy_files_to_folder(train_dataset[\"images\"], os.path.join(train_folder, \"images\"))\n",
    "copy_files_to_folder(train_dataset[\"labels\"], os.path.join(train_folder, \"labels\"))\n",
    "\n",
    "# Copy images and labels to validation folder\n",
    "copy_files_to_folder(val_dataset[\"images\"], os.path.join(val_folder, \"images\"))\n",
    "copy_files_to_folder(val_dataset[\"labels\"], os.path.join(val_folder, \"labels\"))\n",
    "\n",
    "# Print the number of images in the training and validation sets\n",
    "print(\"Number of images in training set:\", len(train_dataset[\"images\"]))\n",
    "print(\"Number of images in validation set:\", len(val_dataset[\"images\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "updating for yolov7 the class id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_class_ids(label_dir):\n",
    "    for filename in os.listdir(label_dir):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(label_dir, filename), \"r\") as file:\n",
    "                lines = file.readlines()\n",
    "                updated_lines = []\n",
    "                for line in lines:\n",
    "                    class_id, *rest = map(float, line.strip().split())\n",
    "                    # Update class IDs\n",
    "                    if class_id == 4:\n",
    "                        updated_class_id = 0\n",
    "                    elif class_id == 5:\n",
    "                        updated_class_id = 1\n",
    "                    elif class_id == 7:\n",
    "                        updated_class_id = 2\n",
    "                    else:\n",
    "                        updated_class_id = class_id\n",
    "                    updated_line = f\"{updated_class_id} {' '.join(map(str, rest))}\\n\"\n",
    "                    updated_lines.append(updated_line)\n",
    "            # Write updated labels back to file\n",
    "            with open(os.path.join(label_dir, filename), \"w\") as file:\n",
    "                file.writelines(updated_lines)\n",
    "\n",
    "# Example usage\n",
    "label_directory = \"data/yolov7-custom/data/train/labels\"\n",
    "update_class_ids(label_directory)\n",
    "label_directory = \"data/yolov7-custom/data/validation/labels\"\n",
    "update_class_ids(label_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python data/yolov7-custom/train.py --workers 1 --device cpu --batch-size 8 --epochs 20 --img 640 640 --data data/yolov7-custom/data/custom_data.yaml --hyp data/yolov7-custom/data/hyp.scratch.custom.yaml --cfg data/yolov7-custom/cfg/training/yolov7-custom.yaml --name data/yolov7-custom/yolov7-custom --weights data/yolov7-custom/yolov7.pt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
